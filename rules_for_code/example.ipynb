{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 说明：\n",
    "### 本规则参考huggingface、openprompt、pytorch等优秀项目的代码，仅供自娱自乐"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "值得说明的是 ####-Name 作为一种身份的标识"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ① 缩进等"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ② 变量、常量等\n",
    "这部分和大多数rules一样\n",
    "常量建议用大写字母\n",
    "变量建议用小写字母\n",
    "尽量用单词或中文拼音的缩写，用_来隔开不同内容"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ③ 类及函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BertConfig(PretrainedConfig):\n",
    "    ####-xbf 注意加r，表示后面跟着的是原始字符串，即 / 不用写成 //\n",
    "    r\"\"\"\n",
    "    This is the configuration class to store the configuration of a :class:`~transformers.BertModel` or a\n",
    "    :class:`~transformers.TFBertModel`. It is used to instantiate a BERT model according to the specified arguments,\n",
    "    defining the model architecture. Instantiating a configuration with the defaults will yield a similar configuration\n",
    "    to that of the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.\n",
    "\n",
    "    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model\n",
    "    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        vocab_file (:obj:`str`):\n",
    "            File containing the vocabulary.\n",
    "        vocab(:obj:`int`, `optional`, defaults to 30522):\n",
    "            Vocabulary size of the BERT model. Defines the number of different tokens that can be represented by the\n",
    "            :obj:`inputs_ids` passed when calling :class:`~transformers.BertModel` or\n",
    "            :class:`~transformers.TFBertModel`.\n",
    "        hidden_size (:obj:`int`, `optional`, defaults to 768):\n",
    "            Dimensionality of the encoder layers and the pooler layer.\n",
    "        参数（:obj:'类型','optional：可选/如果必选就不写就行',defaults to 初始值):### 有关初始值的一些值得说明的点详见python教程\n",
    "            这个参数是什么东西。干什么用。\n",
    "    Examples:: ####-xbf 这个实际上不一定需要，但上面两个非常需要\n",
    "        >>> from transformers import BertModel, BertConfig\n",
    "\n",
    "        >>> # Initializing a BERT bert-base-uncased style configuration\n",
    "        >>> configuration = BertConfig()\n",
    "\n",
    "        >>> # Initializing a model from the bert-base-uncased style configuration\n",
    "        >>> model = BertModel(configuration)\n",
    "\n",
    "        >>> # Accessing the model configuration\n",
    "        >>> configuration = model.config\n",
    "    \"\"\"\n",
    "    model_type = \"bert\"\n",
    "\n",
    "    ####-xbf 参数要一个占一行\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=30522,\n",
    "        hidden_size=768,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        pad_token_id=0,\n",
    "        gradient_checkpointing=False,\n",
    "        position_embedding_type=\"absolute\",\n",
    "        use_cache=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "            ........\n",
    "        :param vocab_size:\n",
    "        :param hidden_size:\n",
    "        :param num_hidden_layers:\n",
    "        :param num_attention_heads:\n",
    "        :param intermediate_size:\n",
    "        :param hidden_act:\n",
    "        :param hidden_dropout_prob:\n",
    "        :param attention_probs_dropout_prob:\n",
    "        :param max_position_embeddings:\n",
    "        :param type_vocab_size:\n",
    "        :param initializer_range:\n",
    "        :param layer_norm_eps:\n",
    "        :param pad_token_id:\n",
    "        :param gradient_checkpointing:\n",
    "        :param position_embedding_type:\n",
    "        :param use_cache:\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        super().__init__(pad_token_id=pad_token_id, **kwargs)# 不同内容块之间要隔一行\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.gradient_checkpointing = gradient_checkpointing\n",
    "        self.position_embedding_type = position_embedding_type\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    @property### 要保证空一行,如果您不懂修饰器，详见本项目的python教程\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens):### 要保证空一行\n",
    "        \"\"\"\n",
    "        Converts a sequence of tokens (string) in a single string.\n",
    "        :param tokens: xxxx\n",
    "        :return:xxxx\n",
    "        \"\"\"\n",
    "        out_string = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
    "\n",
    "        return out_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 函数请参考以下模板\n",
    "def whitespace_tokenize(text):\n",
    "    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\" ####-xbf 一个对功能的说明,也可以写在参数及其返回值说明中（因为方便）\n",
    "    \"\"\"####-xbf 参数及返回值的说明\n",
    "    :param text: xxxx\n",
    "    :return:xxxx\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ④ import 及一些文件声明"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "主要的规则是\n",
    "先import 标准库，再import 一些常用库，最后import 本项目中的其他文件夹中内容"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import data.mm.TAV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ⑤ 注释\n",
    "简单的注释请添加在代码后面"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1) # 输出1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ⑥ 教程类notebook的说明"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ⑦ 说明文档\n",
    "每个目录下都应该有相应的说明文档对功能加以描述"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}