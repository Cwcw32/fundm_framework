[2022-12-11 01:56:06,863][bmrc_v4.py][line:1266][INFO] Namespace(add_note='', batch_size=2, bert_model_type='../../bert/bert-base-uncased', beta=1, checkpoint_path='./model/final_2.pth', data_path='./data', dataset_type='ASTE', epoch_num=40, gat=False, gpu=True, hidden_size=768, infer_rt=False, inference_beta=0.8, learning_rate=0.001, log_path='./log', mode='train', model_name='BMRC', nizhuan=False, save_model_path='./checkpoint/2022-12-11-01-56-05-', task_type='ASTE', train_rt=True, tuning_bert_rate=1e-05, warm_up=0.1, work_nums=1, zhongzi=[5, 77, 89, 32, 66])
[2022-12-11 01:56:06,863][bmrc_v4.py][line:1267][INFO] ####################################
[2022-12-11 01:56:06,863][bmrc_v4.py][line:1268][INFO] ####################################
[2022-12-11 01:56:06,875][bmrc_v4.py][line:1269][INFO] loading data......
[2022-12-11 01:56:09,523][bmrc_v4.py][line:1287][INFO] initial optimizer......
[2022-12-11 01:56:09,559][bmrc_v4.py][line:1297][INFO] New model and optimizer from epoch 1
[2022-12-11 01:56:11,783][bmrc_v4.py][line:1313][INFO] begin training......
[2022-12-11 01:56:11,783][bmrc_v4.py][line:1347][INFO] train
[2022-12-11 01:56:17,833][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[10/114]	 Loss Sum:60.7507	 S_A Loss:7.8118;S_O Loss:7.5292	 A_O Loss:10.7619;O_A Loss:11.6752	 AO_P Loss:0.742	;	 PA_O Loss:10.5938	;	 PO_A Loss:11.6368	;
[2022-12-11 01:56:22,675][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[20/114]	 Loss Sum:35.3745	 S_A Loss:5.8693;S_O Loss:5.929	 A_O Loss:5.7968;O_A Loss:6.1062	 AO_P Loss:0.3877	;	 PA_O Loss:5.5596	;	 PO_A Loss:5.726	;
[2022-12-11 01:56:27,664][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[30/114]	 Loss Sum:16.4484	 S_A Loss:2.8989;S_O Loss:2.5844	 A_O Loss:2.4954;O_A Loss:2.9335	 AO_P Loss:0.2305	;	 PA_O Loss:2.3964	;	 PO_A Loss:2.9092	;
[2022-12-11 01:56:32,606][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[40/114]	 Loss Sum:24.0326	 S_A Loss:2.3075;S_O Loss:3.7402	 A_O Loss:4.1607;O_A Loss:4.6516	 AO_P Loss:0.6135	;	 PA_O Loss:4.1069	;	 PO_A Loss:4.4521	;
[2022-12-11 01:56:37,533][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[50/114]	 Loss Sum:18.1438	 S_A Loss:2.1921;S_O Loss:3.3231	 A_O Loss:3.0939;O_A Loss:3.0911	 AO_P Loss:0.2669	;	 PA_O Loss:3.1356	;	 PO_A Loss:3.041	;
[2022-12-11 01:56:42,475][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[60/114]	 Loss Sum:26.78	 S_A Loss:3.0579;S_O Loss:4.015	 A_O Loss:5.4558;O_A Loss:4.1748	 AO_P Loss:0.4184	;	 PA_O Loss:5.4061	;	 PO_A Loss:4.2519	;
[2022-12-11 01:56:47,564][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[70/114]	 Loss Sum:20.4453	 S_A Loss:2.1901;S_O Loss:3.6138	 A_O Loss:3.4628;O_A Loss:3.8071	 AO_P Loss:0.1363	;	 PA_O Loss:3.6	;	 PO_A Loss:3.6351	;
[2022-12-11 01:56:52,957][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[80/114]	 Loss Sum:15.622	 S_A Loss:3.0152;S_O Loss:2.4673	 A_O Loss:2.662;O_A Loss:2.543	 AO_P Loss:0.0949	;	 PA_O Loss:2.2807	;	 PO_A Loss:2.5588	;
[2022-12-11 01:56:58,020][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[90/114]	 Loss Sum:14.9168	 S_A Loss:1.7623;S_O Loss:3.0794	 A_O Loss:2.6761;O_A Loss:2.1802	 AO_P Loss:0.2206	;	 PA_O Loss:2.8124	;	 PO_A Loss:2.1857	;
[2022-12-11 01:57:03,417][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[100/114]	 Loss Sum:20.3199	 S_A Loss:2.0996;S_O Loss:2.9375	 A_O Loss:3.7477;O_A Loss:3.7108	 AO_P Loss:0.4816	;	 PA_O Loss:3.4707	;	 PO_A Loss:3.8719	;
[2022-12-11 01:57:08,535][bmrc_v4.py][line:1462][INFO] Epoch:[1/40]	 Batch:[110/114]	 Loss Sum:15.9702	 S_A Loss:1.79;S_O Loss:2.5527	 A_O Loss:2.5287;O_A Loss:3.5303	 AO_P Loss:0.3447	;	 PA_O Loss:2.1356	;	 PO_A Loss:3.0882	;
[2022-12-11 01:57:10,658][bmrc_v4.py][line:1483][INFO] dev
