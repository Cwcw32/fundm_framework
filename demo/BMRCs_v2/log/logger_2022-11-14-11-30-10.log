[2022-11-14 11:30:10,343][main.py][line:2119][INFO] Namespace(task_type='ASTE', dataset_type='ASTE', data_path='./data', log_path='./log', save_model_path='./checkpoint/2022-11-14-11-30-10-', model_name='BMRC', work_nums=1, mode='train', checkpoint_path='./model/final_2.pth', bert_model_type='../../bert/bert-base-uncased', hidden_size=768, inference_beta=0.8, gpu=True, epoch_num=30, batch_size=2, learning_rate=0.001, tuning_bert_rate=1e-05, warm_up=0.1, beta=1, add_note='')
[2022-11-14 11:30:10,344][main.py][line:2121][INFO] ####################################
[2022-11-14 11:30:10,344][main.py][line:2122][INFO] ####################################
[2022-11-14 11:30:10,344][main.py][line:2124][INFO] loading data......
[2022-11-14 11:30:11,246][main.py][line:2147][INFO] initial optimizer......
[2022-11-14 11:30:11,255][main.py][line:2159][INFO] New model and optimizer from epoch 1
[2022-11-14 11:30:15,044][main.py][line:2196][INFO] begin training......
[2022-11-14 11:30:15,047][main.py][line:2248][INFO] train
[2022-11-14 11:30:16,976][main.py][line:2390][INFO] Epoch:[1/30]	 Batch:[0/460]	 Loss Sum:100.8424	 forward Loss:21.2887;23.0238	 backward Loss:31.2596;23.1847	 Sentiment Loss:2.0856
[2022-11-14 11:30:57,881][main.py][line:2390][INFO] Epoch:[1/30]	 Batch:[100/460]	 Loss Sum:142.9451	 forward Loss:25.5419;43.8696	 backward Loss:39.5769;29.0786	 Sentiment Loss:4.8781
[2022-11-14 11:31:38,341][main.py][line:2390][INFO] Epoch:[1/30]	 Batch:[200/460]	 Loss Sum:53.6739	 forward Loss:9.8041;13.7797	 backward Loss:13.8406;14.2229	 Sentiment Loss:2.0266
[2022-11-14 11:32:19,064][main.py][line:2390][INFO] Epoch:[1/30]	 Batch:[300/460]	 Loss Sum:62.4988	 forward Loss:13.6533;15.9033	 backward Loss:16.6918;14.3491	 Sentiment Loss:1.9013
[2022-11-14 11:32:59,667][main.py][line:2390][INFO] Epoch:[1/30]	 Batch:[400/460]	 Loss Sum:82.234	 forward Loss:14.5783;24.3402	 backward Loss:13.8328;25.7903	 Sentiment Loss:3.6924
[2022-11-14 11:33:23,715][main.py][line:2549][INFO] dev
[2022-11-14 11:33:40,867][main.py][line:1236][INFO] Triplet - Precision: 0.33478260724007564	Recall: 0.22848664620627107	F1: 0.27160445512062675
[2022-11-14 11:33:40,867][main.py][line:1242][INFO] Aspect - Precision: 0.6554054009769905	Recall: 0.34767024964992743	F1: 0.45433209762617166
[2022-11-14 11:33:40,868][main.py][line:1247][INFO] Opinion - Precision: 0.6216216182615047	Recall: 0.3412462897885867	F1: 0.44061256752737554
[2022-11-14 11:33:40,868][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5270270234660336	Recall: 0.27956989147107564	F1: 0.36533912380423467
[2022-11-14 11:33:40,868][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.39999999826086957	Recall: 0.2729970318308693	F1: 0.32451450784390845
[2022-11-14 11:33:40,870][main.py][line:2564][INFO] test
[2022-11-14 11:34:03,955][main.py][line:1236][INFO] Triplet - Precision: 0.39273927263122355	Recall: 0.24285714236151604	F1: 0.30012563045256824
[2022-11-14 11:34:03,956][main.py][line:1242][INFO] Aspect - Precision: 0.7019230735484467	Recall: 0.3492822958151141	F1: 0.46645322889935925
[2022-11-14 11:34:03,956][main.py][line:1247][INFO] Opinion - Precision: 0.7372548990695886	Recall: 0.38367346860474805	F1: 0.5046975349727
[2022-11-14 11:34:03,956][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5817307664339867	Recall: 0.28947368351800556	F1: 0.38658102468178573
[2022-11-14 11:34:03,956][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.45544554305133483	Recall: 0.28163265248646396	F1: 0.3480449241525434
[2022-11-14 11:34:03,958][main.py][line:2576][INFO] Model saved after epoch 1
[2022-11-14 11:34:03,960][main.py][line:2248][INFO] train
[2022-11-14 11:34:04,406][main.py][line:2390][INFO] Epoch:[2/30]	 Batch:[0/460]	 Loss Sum:47.9871	 forward Loss:11.0279;14.2895	 backward Loss:9.3794;11.0376	 Sentiment Loss:2.2527
[2022-11-14 11:34:47,085][main.py][line:2390][INFO] Epoch:[2/30]	 Batch:[100/460]	 Loss Sum:19.4811	 forward Loss:4.907;3.9933	 backward Loss:4.988;4.2719	 Sentiment Loss:1.321
[2022-11-14 11:35:29,023][main.py][line:2390][INFO] Epoch:[2/30]	 Batch:[200/460]	 Loss Sum:25.0585	 forward Loss:3.2824;9.9963	 backward Loss:4.9119;5.81	 Sentiment Loss:1.0581
[2022-11-14 11:36:13,345][main.py][line:2390][INFO] Epoch:[2/30]	 Batch:[300/460]	 Loss Sum:68.6076	 forward Loss:9.6085;28.5664	 backward Loss:8.7986;20.6498	 Sentiment Loss:0.9843
[2022-11-14 11:36:59,336][main.py][line:2390][INFO] Epoch:[2/30]	 Batch:[400/460]	 Loss Sum:94.4823	 forward Loss:13.4879;41.0594	 backward Loss:19.565;17.1419	 Sentiment Loss:3.2282
[2022-11-14 11:37:26,437][main.py][line:2549][INFO] dev
[2022-11-14 11:37:52,900][main.py][line:1236][INFO] Triplet - Precision: 0.45514950014900496	Recall: 0.4065281887046641	F1: 0.42946658488575057
[2022-11-14 11:37:52,900][main.py][line:1242][INFO] Aspect - Precision: 0.7256637136032579	Recall: 0.5878136179648258	F1: 0.6495044534304324
[2022-11-14 11:37:52,901][main.py][line:1247][INFO] Opinion - Precision: 0.7666666634722222	Recall: 0.5459940636617386	F1: 0.6377811410364469
[2022-11-14 11:37:52,901][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6327433600321091	Recall: 0.5125448010303054	F1: 0.5663361369281841
[2022-11-14 11:37:52,901][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.5049833870266333	Recall: 0.4510385743292624	F1: 0.476488528311957
[2022-11-14 11:37:52,904][main.py][line:2564][INFO] test
[2022-11-14 11:38:32,817][main.py][line:1236][INFO] Triplet - Precision: 0.47087378526486945	Recall: 0.39591836653894213	F1: 0.43015471342872674
[2022-11-14 11:38:32,817][main.py][line:1242][INFO] Aspect - Precision: 0.7181818160055097	Recall: 0.5669856445765894	F1: 0.6336893447986336
[2022-11-14 11:38:32,818][main.py][line:1247][INFO] Opinion - Precision: 0.8243626038969898	Recall: 0.5938775498084131	F1: 0.6903909706426715
[2022-11-14 11:38:32,818][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5848484830762167	Recall: 0.4617224869336783	F1: 0.516042286289756
[2022-11-14 11:38:32,818][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.5558252413693562	Recall: 0.46734693782174097	F1: 0.5077600347643259
[2022-11-14 11:38:32,823][main.py][line:2576][INFO] Model saved after epoch 2
[2022-11-14 11:38:32,827][main.py][line:2248][INFO] train
[2022-11-14 11:38:33,351][main.py][line:2390][INFO] Epoch:[3/30]	 Batch:[0/460]	 Loss Sum:23.6073	 forward Loss:6.6751;5.4304	 backward Loss:7.6904;3.3344	 Sentiment Loss:0.4771
[2022-11-14 11:39:18,810][main.py][line:2390][INFO] Epoch:[3/30]	 Batch:[100/460]	 Loss Sum:8.2115	 forward Loss:2.7146;0.3796	 backward Loss:1.8342;3.1199	 Sentiment Loss:0.1633
[2022-11-14 11:40:04,699][main.py][line:2390][INFO] Epoch:[3/30]	 Batch:[200/460]	 Loss Sum:12.3376	 forward Loss:3.9292;2.6685	 backward Loss:3.5434;1.8074	 Sentiment Loss:0.3891
[2022-11-14 11:40:50,777][main.py][line:2390][INFO] Epoch:[3/30]	 Batch:[300/460]	 Loss Sum:21.0435	 forward Loss:5.2789;5.0316	 backward Loss:6.6128;3.2644	 Sentiment Loss:0.8558
[2022-11-14 11:41:36,657][main.py][line:2390][INFO] Epoch:[3/30]	 Batch:[400/460]	 Loss Sum:20.9149	 forward Loss:5.8689;3.2603	 backward Loss:3.9404;7.7101	 Sentiment Loss:0.1352
[2022-11-14 11:42:03,728][main.py][line:2549][INFO] dev
[2022-11-14 11:42:31,453][main.py][line:1236][INFO] Triplet - Precision: 0.40277777665895065	Recall: 0.4302670610377832	F1: 0.416068365922186
[2022-11-14 11:42:31,454][main.py][line:1242][INFO] Aspect - Precision: 0.7656249970092773	Recall: 0.7025089580555235	F1: 0.732709778559166
[2022-11-14 11:42:31,454][main.py][line:1247][INFO] Opinion - Precision: 0.7324414691222694	Recall: 0.6498516301191346	F1: 0.6886787449026587
[2022-11-14 11:42:31,454][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6015624976501465	Recall: 0.5519713241864828	F1: 0.5757004333518171
[2022-11-14 11:42:31,455][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.522222220771605	Recall: 0.5578634998282982	F1: 0.5394543053097507
[2022-11-14 11:42:31,458][main.py][line:2564][INFO] test
[2022-11-14 11:43:12,994][main.py][line:1236][INFO] Triplet - Precision: 0.44585987166484103	Recall: 0.428571427696793	F1: 0.4370442443436888
[2022-11-14 11:43:12,995][main.py][line:1242][INFO] Aspect - Precision: 0.7576601650204452	Recall: 0.6507177017925414	F1: 0.7001282012098361
[2022-11-14 11:43:12,995][main.py][line:1247][INFO] Opinion - Precision: 0.7651331700602102	Recall: 0.6448979578675552	F1: 0.6998887601146015
[2022-11-14 11:43:12,996][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5793871850156346	Recall: 0.4976076543119434	F1: 0.5353920368978112
[2022-11-14 11:43:12,996][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.564755837442132	Recall: 0.5428571417492711	F1: 0.5535895094496137
[2022-11-14 11:43:12,999][main.py][line:2248][INFO] train
[2022-11-14 11:43:13,502][main.py][line:2390][INFO] Epoch:[4/30]	 Batch:[0/460]	 Loss Sum:31.1268	 forward Loss:5.6951;12.4753	 backward Loss:8.0612;2.6457	 Sentiment Loss:2.2495
[2022-11-14 11:43:58,610][main.py][line:2390][INFO] Epoch:[4/30]	 Batch:[100/460]	 Loss Sum:32.3179	 forward Loss:4.7627;15.0071	 backward Loss:7.6737;3.5218	 Sentiment Loss:1.3525
[2022-11-14 11:44:44,047][main.py][line:2390][INFO] Epoch:[4/30]	 Batch:[200/460]	 Loss Sum:5.2196	 forward Loss:1.0702;0.8634	 backward Loss:1.8663;0.5626	 Sentiment Loss:0.857
[2022-11-14 11:45:29,773][main.py][line:2390][INFO] Epoch:[4/30]	 Batch:[300/460]	 Loss Sum:9.7031	 forward Loss:0.0805;4.0375	 backward Loss:1.7535;3.1087	 Sentiment Loss:0.723
[2022-11-14 11:46:15,540][main.py][line:2390][INFO] Epoch:[4/30]	 Batch:[400/460]	 Loss Sum:20.9095	 forward Loss:1.0715;12.0394	 backward Loss:1.4317;2.3336	 Sentiment Loss:4.0332
[2022-11-14 11:46:42,578][main.py][line:2549][INFO] dev
[2022-11-14 11:47:10,526][main.py][line:1236][INFO] Triplet - Precision: 0.5103448258263972	Recall: 0.43916913816270287	F1: 0.4720888154987443
[2022-11-14 11:47:10,526][main.py][line:1242][INFO] Aspect - Precision: 0.7773279320755955	Recall: 0.6881720405441862	F1: 0.7300375218887581
[2022-11-14 11:47:10,526][main.py][line:1247][INFO] Opinion - Precision: 0.7557251879552473	Recall: 0.587537090244697	F1: 0.6611013420256115
[2022-11-14 11:47:10,527][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6518218597092232	Recall: 0.5770609298313228	F1: 0.6121667999035412
[2022-11-14 11:47:10,527][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6034482737812129	Recall: 0.5192878322869797	F1: 0.5582132171378202
[2022-11-14 11:47:10,529][main.py][line:2564][INFO] test
[2022-11-14 11:47:50,317][main.py][line:1236][INFO] Triplet - Precision: 0.5710843359732908	Recall: 0.4836734684006664	F1: 0.5237564083543061
[2022-11-14 11:47:50,317][main.py][line:1242][INFO] Aspect - Precision: 0.8276836134811197	Recall: 0.7009569361221126	F1: 0.7590668589831162
[2022-11-14 11:47:50,317][main.py][line:1247][INFO] Opinion - Precision: 0.820580472768917	Recall: 0.6346938762557268	F1: 0.7157647539216873
[2022-11-14 11:47:50,317][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6638418060343452	Recall: 0.5622009555928207	F1: 0.6088077920149558
[2022-11-14 11:47:50,317][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6843373477485847	Recall: 0.5795918355518535	F1: 0.6276238114396042
[2022-11-14 11:47:50,320][main.py][line:2576][INFO] Model saved after epoch 4
[2022-11-14 11:47:50,323][main.py][line:2248][INFO] train
[2022-11-14 11:47:50,815][main.py][line:2390][INFO] Epoch:[5/30]	 Batch:[0/460]	 Loss Sum:7.5677	 forward Loss:5.0472;0.2227	 backward Loss:1.2724;0.4944	 Sentiment Loss:0.531
[2022-11-14 11:48:35,396][main.py][line:2390][INFO] Epoch:[5/30]	 Batch:[100/460]	 Loss Sum:7.9888	 forward Loss:0.8647;0.5483	 backward Loss:2.7906;2.1093	 Sentiment Loss:1.6758
[2022-11-14 11:49:20,687][main.py][line:2390][INFO] Epoch:[5/30]	 Batch:[200/460]	 Loss Sum:16.7515	 forward Loss:1.7692;4.7525	 backward Loss:7.4084;2.2931	 Sentiment Loss:0.5282
[2022-11-14 11:50:05,983][main.py][line:2390][INFO] Epoch:[5/30]	 Batch:[300/460]	 Loss Sum:15.4998	 forward Loss:4.4827;4.9487	 backward Loss:5.0533;0.8699	 Sentiment Loss:0.1451
[2022-11-14 11:50:51,715][main.py][line:2390][INFO] Epoch:[5/30]	 Batch:[400/460]	 Loss Sum:6.6584	 forward Loss:0.1058;4.4249	 backward Loss:0.1208;1.2713	 Sentiment Loss:0.7356
[2022-11-14 11:51:18,335][main.py][line:2549][INFO] dev
[2022-11-14 11:51:42,531][main.py][line:1236][INFO] Triplet - Precision: 0.5559105413549184	Recall: 0.5163204732453398	F1: 0.5353841144194006
[2022-11-14 11:51:42,532][main.py][line:1242][INFO] Aspect - Precision: 0.7837837807575916	Recall: 0.7275985637003636	F1: 0.7546463380346307
[2022-11-14 11:51:42,532][main.py][line:1247][INFO] Opinion - Precision: 0.7659574440923494	Recall: 0.640949552994215	F1: 0.6978993401419641
[2022-11-14 11:51:42,532][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6602316576825032	Recall: 0.6129032236096659	F1: 0.6356872306702281
[2022-11-14 11:51:42,532][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6198083047290469	Recall: 0.5756676540781376	F1: 0.5969225757684651
[2022-11-14 11:51:42,534][main.py][line:2564][INFO] test
[2022-11-14 11:52:17,902][main.py][line:1236][INFO] Triplet - Precision: 0.6115107899004537	Recall: 0.5204081622032487	F1: 0.5622927765308912
[2022-11-14 11:52:17,903][main.py][line:1242][INFO] Aspect - Precision: 0.8176795557522665	Recall: 0.7081339695977656	F1: 0.7589738596058487
[2022-11-14 11:52:17,903][main.py][line:1247][INFO] Opinion - Precision: 0.8419689097358318	Recall: 0.6632653047688464	F1: 0.7420086377737267
[2022-11-14 11:52:17,903][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6878453019672782	Recall: 0.5956937784792015	F1: 0.638461039402097
[2022-11-14 11:52:17,903][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7074340510613092	Recall: 0.6020408150978759	F1: 0.6504956429295022
[2022-11-14 11:52:17,906][main.py][line:2576][INFO] Model saved after epoch 5
[2022-11-14 11:52:17,909][main.py][line:2248][INFO] train
[2022-11-14 11:52:18,417][main.py][line:2390][INFO] Epoch:[6/30]	 Batch:[0/460]	 Loss Sum:6.7854	 forward Loss:0.6671;2.6804	 backward Loss:0.6056;2.6304	 Sentiment Loss:0.2019
[2022-11-14 11:53:02,775][main.py][line:2390][INFO] Epoch:[6/30]	 Batch:[100/460]	 Loss Sum:17.0811	 forward Loss:2.9421;8.0502	 backward Loss:3.0766;2.3159	 Sentiment Loss:0.6963
[2022-11-14 11:53:46,727][main.py][line:2390][INFO] Epoch:[6/30]	 Batch:[200/460]	 Loss Sum:12.7987	 forward Loss:6.0901;0.8148	 backward Loss:3.4876;2.3183	 Sentiment Loss:0.088
[2022-11-14 11:54:29,135][main.py][line:2390][INFO] Epoch:[6/30]	 Batch:[300/460]	 Loss Sum:3.4045	 forward Loss:1.2342;0.1728	 backward Loss:0.5825;0.4248	 Sentiment Loss:0.9903
[2022-11-14 11:55:12,826][main.py][line:2390][INFO] Epoch:[6/30]	 Batch:[400/460]	 Loss Sum:12.4451	 forward Loss:0.2608;4.083	 backward Loss:6.1913;0.9119	 Sentiment Loss:0.9981
[2022-11-14 11:55:40,384][main.py][line:2549][INFO] dev
[2022-11-14 11:56:14,312][main.py][line:1236][INFO] Triplet - Precision: 0.5544217668216946	Recall: 0.4836795237873011	F1: 0.5166397542506446
[2022-11-14 11:56:14,312][main.py][line:1242][INFO] Aspect - Precision: 0.8185483837961759	Recall: 0.7275985637003636	F1: 0.7703979807801472
[2022-11-14 11:56:14,312][main.py][line:1247][INFO] Opinion - Precision: 0.7712177093313	Recall: 0.6201780397027358	F1: 0.6874995036306788
[2022-11-14 11:56:14,312][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6774193521071801	Recall: 0.6021505354761629	F1: 0.6375706568061246
[2022-11-14 11:56:14,313][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.642857140670554	Recall: 0.5608308588699381	F1: 0.5990486287912795
[2022-11-14 11:56:14,315][main.py][line:2564][INFO] test
[2022-11-14 11:56:52,249][main.py][line:1236][INFO] Triplet - Precision: 0.6155660362840424	Recall: 0.5326530601374427	F1: 0.5711154750996676
[2022-11-14 11:56:52,250][main.py][line:1242][INFO] Aspect - Precision: 0.8495821703354257	Recall: 0.7296650700247247	F1: 0.7850702859332417
[2022-11-14 11:56:52,250][main.py][line:1247][INFO] Opinion - Precision: 0.8358585837478318	Recall: 0.6755102027030404	F1: 0.7471778335128545
[2022-11-14 11:56:52,250][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.7158774353318177	Recall: 0.6148325344142762	F1: 0.6615181626992004
[2022-11-14 11:56:52,250][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7146226398240032	Recall: 0.6183673456768013	F1: 0.6630191948109779
[2022-11-14 11:56:52,253][main.py][line:2248][INFO] train
[2022-11-14 11:56:52,756][main.py][line:2390][INFO] Epoch:[7/30]	 Batch:[0/460]	 Loss Sum:1.2367	 forward Loss:0.2586;0.4359	 backward Loss:0.4248;0.1122	 Sentiment Loss:0.0052
[2022-11-14 11:57:35,101][main.py][line:2390][INFO] Epoch:[7/30]	 Batch:[100/460]	 Loss Sum:1.7428	 forward Loss:0.0376;0.6593	 backward Loss:0.0135;1.0133	 Sentiment Loss:0.0191
[2022-11-14 11:58:17,061][main.py][line:2390][INFO] Epoch:[7/30]	 Batch:[200/460]	 Loss Sum:8.0278	 forward Loss:3.2695;1.3475	 backward Loss:2.343;0.7538	 Sentiment Loss:0.3139
[2022-11-14 11:58:59,947][main.py][line:2390][INFO] Epoch:[7/30]	 Batch:[300/460]	 Loss Sum:5.1538	 forward Loss:2.4661;0.2403	 backward Loss:0.1224;0.7548	 Sentiment Loss:1.5702
[2022-11-14 11:59:42,780][main.py][line:2390][INFO] Epoch:[7/30]	 Batch:[400/460]	 Loss Sum:0.7116	 forward Loss:0.2033;0.0338	 backward Loss:0.1086;0.3016	 Sentiment Loss:0.0643
[2022-11-14 12:00:07,936][main.py][line:2549][INFO] dev
[2022-11-14 12:00:33,591][main.py][line:1236][INFO] Triplet - Precision: 0.5620689635790725	Recall: 0.4836795237873011	F1: 0.5199357052982276
[2022-11-14 12:00:33,591][main.py][line:1242][INFO] Aspect - Precision: 0.8104838676996619	Recall: 0.720430104944695	F1: 0.762807847981631
[2022-11-14 12:00:33,592][main.py][line:1247][INFO] Opinion - Precision: 0.7985347956097627	Recall: 0.6468842710774948	F1: 0.7147536015214386
[2022-11-14 12:00:33,592][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.657258061865895	Recall: 0.5842293885869915	F1: 0.618595324809838
[2022-11-14 12:00:33,592][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6793103424851368	Recall: 0.5845697312030572	F1: 0.6283886555104168
[2022-11-14 12:00:33,595][main.py][line:2564][INFO] test
[2022-11-14 12:01:11,371][main.py][line:1236][INFO] Triplet - Precision: 0.6342710981220688	Recall: 0.5061224479466889	F1: 0.5629960998147756
[2022-11-14 12:01:11,372][main.py][line:1242][INFO] Aspect - Precision: 0.8670520206154566	Recall: 0.717703347565303	F1: 0.7853398165212413
[2022-11-14 12:01:11,372][main.py][line:1247][INFO] Opinion - Precision: 0.8605898100252284	Recall: 0.6551020394793836	F1: 0.7439160775706847
[2022-11-14 12:01:11,372][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.7109826569046744	Recall: 0.5885167450035484	F1: 0.6439785603468631
[2022-11-14 12:01:11,372][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7595907908961872	Recall: 0.6061224477426073	F1: 0.6742333299821566
[2022-11-14 12:01:11,375][main.py][line:2248][INFO] train
[2022-11-14 12:01:11,878][main.py][line:2390][INFO] Epoch:[8/30]	 Batch:[0/460]	 Loss Sum:9.3824	 forward Loss:0.1741;4.0257	 backward Loss:4.1607;0.5758	 Sentiment Loss:0.4461
[2022-11-14 12:01:53,428][main.py][line:2390][INFO] Epoch:[8/30]	 Batch:[100/460]	 Loss Sum:2.9805	 forward Loss:0.2025;0.0994	 backward Loss:0.5072;0.5657	 Sentiment Loss:1.6058
[2022-11-14 12:02:35,801][main.py][line:2390][INFO] Epoch:[8/30]	 Batch:[200/460]	 Loss Sum:0.7472	 forward Loss:0.0219;0.0891	 backward Loss:0.5486;0.0511	 Sentiment Loss:0.0365
[2022-11-14 12:03:18,118][main.py][line:2390][INFO] Epoch:[8/30]	 Batch:[300/460]	 Loss Sum:0.2974	 forward Loss:0.1249;0.0796	 backward Loss:0.0592;0.0228	 Sentiment Loss:0.0109
[2022-11-14 12:04:00,301][main.py][line:2390][INFO] Epoch:[8/30]	 Batch:[400/460]	 Loss Sum:0.1925	 forward Loss:0.0353;0.0743	 backward Loss:0.0343;0.0339	 Sentiment Loss:0.0147
[2022-11-14 12:04:25,665][main.py][line:2549][INFO] dev
[2022-11-14 12:04:52,116][main.py][line:1236][INFO] Triplet - Precision: 0.5172413776888986	Recall: 0.4896142418705809	F1: 0.5030482793310658
[2022-11-14 12:04:52,116][main.py][line:1242][INFO] Aspect - Precision: 0.7832699589989736	Recall: 0.7383512518338665	F1: 0.7601470991070942
[2022-11-14 12:04:52,117][main.py][line:1247][INFO] Opinion - Precision: 0.76369862752158	Recall: 0.6617210662856942	F1: 0.7090615034845683
[2022-11-14 12:04:52,117][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6425855488875074	Recall: 0.6057347648539972	F1: 0.6236157342973189
[2022-11-14 12:04:52,117][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6175548569982606	Recall: 0.5845697312030572	F1: 0.6006092546432994
[2022-11-14 12:04:52,121][main.py][line:2564][INFO] test
[2022-11-14 12:05:29,927][main.py][line:1236][INFO] Triplet - Precision: 0.6036446455497844	Recall: 0.5408163254269055	F1: 0.5705054206235579
[2022-11-14 12:05:29,927][main.py][line:1242][INFO] Aspect - Precision: 0.8434065910895423	Recall: 0.7344497590084934	F1: 0.7851657407856321
[2022-11-14 12:05:29,927][main.py][line:1247][INFO] Opinion - Precision: 0.8249400459833572	Recall: 0.7020408148937942	F1: 0.7585441542678198
[2022-11-14 12:05:29,927][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6923076904057481	Recall: 0.6028708119548545	F1: 0.6445007795086293
[2022-11-14 12:05:29,927][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.710706148722765	Recall: 0.6367346925780925	F1: 0.6716894892969387
[2022-11-14 12:05:29,930][main.py][line:2248][INFO] train
[2022-11-14 12:05:30,416][main.py][line:2390][INFO] Epoch:[9/30]	 Batch:[0/460]	 Loss Sum:6.831	 forward Loss:0.0734;2.7384	 backward Loss:2.2655;0.3768	 Sentiment Loss:1.3769
[2022-11-14 12:06:12,416][main.py][line:2390][INFO] Epoch:[9/30]	 Batch:[100/460]	 Loss Sum:2.7567	 forward Loss:1.6499;0.2032	 backward Loss:0.21;0.3448	 Sentiment Loss:0.3489
[2022-11-14 12:06:55,079][main.py][line:2390][INFO] Epoch:[9/30]	 Batch:[200/460]	 Loss Sum:5.4042	 forward Loss:0.0037;0.1287	 backward Loss:1.3744;0.4568	 Sentiment Loss:3.4406
[2022-11-14 12:07:37,231][main.py][line:2390][INFO] Epoch:[9/30]	 Batch:[300/460]	 Loss Sum:2.1674	 forward Loss:0.9637;0.4259	 backward Loss:0.2191;0.1161	 Sentiment Loss:0.4426
[2022-11-14 12:08:19,892][main.py][line:2390][INFO] Epoch:[9/30]	 Batch:[400/460]	 Loss Sum:1.9652	 forward Loss:0.0201;1.6723	 backward Loss:0.1885;0.0818	 Sentiment Loss:0.0024
[2022-11-14 12:08:45,070][main.py][line:2549][INFO] dev
[2022-11-14 12:09:10,497][main.py][line:1236][INFO] Triplet - Precision: 0.5540983588390218	Recall: 0.5014836780371404	F1: 0.5264792503813888
[2022-11-14 12:09:10,497][main.py][line:1242][INFO] Aspect - Precision: 0.7884615354289941	Recall: 0.7347670224560322	F1: 0.7606674013241566
[2022-11-14 12:09:10,497][main.py][line:1247][INFO] Opinion - Precision: 0.7900355843770975	Recall: 0.6587537072440542	F1: 0.7184461037225488
[2022-11-14 12:09:10,498][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6499999975	Recall: 0.6057347648539972	F1: 0.6270866968106111
[2022-11-14 12:09:10,498][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6491803257403924	Recall: 0.587537090244697	F1: 0.616821929227604
[2022-11-14 12:09:10,501][main.py][line:2564][INFO] test
[2022-11-14 12:09:42,881][main.py][line:1236][INFO] Triplet - Precision: 0.6473551620973421	Recall: 0.52448979484798	F1: 0.5794809021610307
[2022-11-14 12:09:42,881][main.py][line:1242][INFO] Aspect - Precision: 0.8643067821111894	Recall: 0.7009569361221126	F1: 0.7741078257255157
[2022-11-14 12:09:42,881][main.py][line:1247][INFO] Opinion - Precision: 0.8556149709742915	Recall: 0.6530612231570179	F1: 0.7407402480391629
[2022-11-14 12:09:42,881][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.7345132721695774	Recall: 0.5956937784792015	F1: 0.6578594772876544
[2022-11-14 12:09:42,882][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.740554154305909	Recall: 0.5999999987755102	F1: 0.6629081849491913
[2022-11-14 12:09:42,884][main.py][line:2248][INFO] train
[2022-11-14 12:09:43,338][main.py][line:2390][INFO] Epoch:[10/30]	 Batch:[0/460]	 Loss Sum:0.4209	 forward Loss:0.0008;0.043	 backward Loss:0.0017;0.2879	 Sentiment Loss:0.0876
[2022-11-14 12:10:30,161][main.py][line:2390][INFO] Epoch:[10/30]	 Batch:[100/460]	 Loss Sum:0.9589	 forward Loss:0.8463;0.0095	 backward Loss:0.0583;0.0296	 Sentiment Loss:0.0152
[2022-11-14 12:11:39,260][main.py][line:2390][INFO] Epoch:[10/30]	 Batch:[200/460]	 Loss Sum:0.2692	 forward Loss:0.0008;0.0101	 backward Loss:0.001;0.0505	 Sentiment Loss:0.2069
[2022-11-14 12:12:54,364][main.py][line:2390][INFO] Epoch:[10/30]	 Batch:[300/460]	 Loss Sum:0.6719	 forward Loss:0.3284;0.043	 backward Loss:0.0635;0.2145	 Sentiment Loss:0.0224
[2022-11-14 12:13:45,681][main.py][line:2390][INFO] Epoch:[10/30]	 Batch:[400/460]	 Loss Sum:1.342	 forward Loss:0.0628;0.097	 backward Loss:0.1171;0.0449	 Sentiment Loss:1.0202
[2022-11-14 12:14:10,964][main.py][line:2549][INFO] dev
[2022-11-14 12:14:28,080][main.py][line:1236][INFO] Triplet - Precision: 0.5704225332027376	Recall: 0.48071216474566125	F1: 0.5217386323969239
[2022-11-14 12:14:28,080][main.py][line:1242][INFO] Aspect - Precision: 0.7918367314618909	Recall: 0.6953404992998549	F1: 0.7404575145463986
[2022-11-14 12:14:28,080][main.py][line:1247][INFO] Opinion - Precision: 0.8326996166057049	Recall: 0.6498516301191346	F1: 0.7299995051725543
[2022-11-14 12:14:28,080][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.661224487097043	Recall: 0.5806451592091572	F1: 0.6183201104324854
[2022-11-14 12:14:28,080][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6690140821513588	Recall: 0.563798217911578	F1: 0.6119157657618233
[2022-11-14 12:14:28,082][main.py][line:2564][INFO] test
[2022-11-14 12:15:01,861][main.py][line:1236][INFO] Triplet - Precision: 0.6632653044304456	Recall: 0.5306122438150771	F1: 0.5895686658340941
[2022-11-14 12:15:01,861][main.py][line:1242][INFO] Aspect - Precision: 0.852173910573409	Recall: 0.7033492806139969	F1: 0.7706417043919986
[2022-11-14 12:15:01,862][main.py][line:1247][INFO] Opinion - Precision: 0.8733153615274518	Recall: 0.6612244884464806	F1: 0.7526127482214006
[2022-11-14 12:15:01,862][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.7304347804914934	Recall: 0.6028708119548545	F1: 0.6605499615613616
[2022-11-14 12:15:01,862][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7525510184883902	Recall: 0.6020408150978759	F1: 0.6689337450191581
[2022-11-14 12:15:01,866][main.py][line:2248][INFO] train
[2022-11-14 12:15:02,421][main.py][line:2390][INFO] Epoch:[11/30]	 Batch:[0/460]	 Loss Sum:0.521	 forward Loss:0.0103;0.2028	 backward Loss:0.0014;0.1395	 Sentiment Loss:0.1671
[2022-11-14 12:16:25,966][main.py][line:2390][INFO] Epoch:[11/30]	 Batch:[100/460]	 Loss Sum:0.8971	 forward Loss:0.0112;0.6715	 backward Loss:0.0172;0.1932	 Sentiment Loss:0.004
[2022-11-14 12:17:51,952][main.py][line:2390][INFO] Epoch:[11/30]	 Batch:[200/460]	 Loss Sum:0.8127	 forward Loss:0.0008;0.3471	 backward Loss:0.0721;0.305	 Sentiment Loss:0.0878
[2022-11-14 12:19:31,758][main.py][line:2390][INFO] Epoch:[11/30]	 Batch:[300/460]	 Loss Sum:17.4503	 forward Loss:0.3962;11.6237	 backward Loss:5.2649;0.1085	 Sentiment Loss:0.057
[2022-11-14 12:20:29,498][main.py][line:2390][INFO] Epoch:[11/30]	 Batch:[400/460]	 Loss Sum:2.918	 forward Loss:0.0958;2.3008	 backward Loss:0.4739;0.0454	 Sentiment Loss:0.002
[2022-11-14 12:21:48,770][main.py][line:2549][INFO] dev
[2022-11-14 12:22:35,185][main.py][line:1236][INFO] Triplet - Precision: 0.5457627100143637	Recall: 0.47774480570402134	F1: 0.5094931714824203
[2022-11-14 12:22:35,186][main.py][line:1242][INFO] Aspect - Precision: 0.8097165959120786	Recall: 0.7168458755668606	F1: 0.7604557727236562
[2022-11-14 12:22:35,186][main.py][line:1247][INFO] Opinion - Precision: 0.7833934989769188	Recall: 0.6439169120358549	F1: 0.7068398933520005
[2022-11-14 12:22:35,186][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6680161916274648	Recall: 0.5913978473426601	F1: 0.6273759253209873
[2022-11-14 12:22:35,186][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6406779639299052	Recall: 0.5608308588699381	F1: 0.5981007661386534
[2022-11-14 12:22:35,190][main.py][line:2564][INFO] test
[2022-11-14 12:23:33,836][main.py][line:1236][INFO] Triplet - Precision: 0.6594202882622698	Recall: 0.5571428560058309	F1: 0.6039818030830691
[2022-11-14 12:23:33,836][main.py][line:1242][INFO] Aspect - Precision: 0.858333330949074	Recall: 0.7392344479922621	F1: 0.7943439737448676
[2022-11-14 12:23:33,837][main.py][line:1247][INFO] Opinion - Precision: 0.8652849718515934	Recall: 0.6816326516701374	F1: 0.7625565829322842
[2022-11-14 12:23:33,837][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.747222220146605	Recall: 0.6435406683168884	F1: 0.6915162105131085
[2022-11-14 12:23:33,837][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7439613508599967	Recall: 0.6285714272886297	F1: 0.6814154312302936
[2022-11-14 12:23:33,841][main.py][line:2248][INFO] train
[2022-11-14 12:23:34,840][main.py][line:2390][INFO] Epoch:[12/30]	 Batch:[0/460]	 Loss Sum:0.5081	 forward Loss:0.0306;0.0065	 backward Loss:0.4042;0.0614	 Sentiment Loss:0.0054
[2022-11-14 12:24:55,554][main.py][line:2390][INFO] Epoch:[12/30]	 Batch:[100/460]	 Loss Sum:0.1948	 forward Loss:0.0072;0.1115	 backward Loss:0.0493;0.0242	 Sentiment Loss:0.0025
[2022-11-14 12:25:52,385][main.py][line:2390][INFO] Epoch:[12/30]	 Batch:[200/460]	 Loss Sum:0.6452	 forward Loss:0.1238;0.2615	 backward Loss:0.0602;0.1662	 Sentiment Loss:0.0335
[2022-11-14 12:26:50,907][main.py][line:2390][INFO] Epoch:[12/30]	 Batch:[300/460]	 Loss Sum:0.6951	 forward Loss:0.0534;0.2985	 backward Loss:0.1839;0.0726	 Sentiment Loss:0.0867
[2022-11-14 12:27:43,079][main.py][line:2390][INFO] Epoch:[12/30]	 Batch:[400/460]	 Loss Sum:0.0346	 forward Loss:0.0171;0.0056	 backward Loss:0.0046;0.0036	 Sentiment Loss:0.0037
[2022-11-14 12:28:05,919][main.py][line:2549][INFO] dev
[2022-11-14 12:28:20,769][main.py][line:1236][INFO] Triplet - Precision: 0.60350876981225	Recall: 0.5103857551620601	F1: 0.5530541640961438
[2022-11-14 12:28:20,769][main.py][line:1242][INFO] Aspect - Precision: 0.8148148114616675	Recall: 0.709677416811192	F1: 0.7586201891270274
[2022-11-14 12:28:20,769][main.py][line:1247][INFO] Opinion - Precision: 0.817843863130692	Recall: 0.6528189891607745	F1: 0.7260721111604617
[2022-11-14 12:28:20,769][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6954732481667768	Recall: 0.6057347648539972	F1: 0.6475090784416855
[2022-11-14 12:28:20,769][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6807017519975377	Recall: 0.5756676540781376	F1: 0.6237937137078632
[2022-11-14 12:28:20,769][main.py][line:2564][INFO] test
[2022-11-14 12:28:42,493][main.py][line:1236][INFO] Triplet - Precision: 0.6515151498699112	Recall: 0.5265306111703457	F1: 0.5823922808375195
[2022-11-14 12:28:42,493][main.py][line:1242][INFO] Aspect - Precision: 0.8501440897690372	Recall: 0.7057416251058812	F1: 0.7712413323562501
[2022-11-14 12:28:42,493][main.py][line:1247][INFO] Opinion - Precision: 0.8713136705862904	Recall: 0.6632653047688464	F1: 0.7531860659617118
[2022-11-14 12:28:42,493][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.729106626140903	Recall: 0.6052631564467389	F1: 0.6614374110747446
[2022-11-14 12:28:42,493][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7449494930683094	Recall: 0.6020408150978759	F1: 0.6659137253441904
[2022-11-14 12:28:42,493][main.py][line:2576][INFO] Model saved after epoch 12
[2022-11-14 12:28:42,508][main.py][line:2248][INFO] train
[2022-11-14 12:28:42,928][main.py][line:2390][INFO] Epoch:[13/30]	 Batch:[0/460]	 Loss Sum:0.1194	 forward Loss:0.0075;0.0319	 backward Loss:0.0226;0.0439	 Sentiment Loss:0.0134
[2022-11-14 12:29:21,364][main.py][line:2390][INFO] Epoch:[13/30]	 Batch:[100/460]	 Loss Sum:1.2793	 forward Loss:0.0122;0.0575	 backward Loss:1.0781;0.1307	 Sentiment Loss:0.0008
[2022-11-14 12:29:59,703][main.py][line:2390][INFO] Epoch:[13/30]	 Batch:[200/460]	 Loss Sum:0.2049	 forward Loss:0.0048;0.0412	 backward Loss:0.0037;0.1541	 Sentiment Loss:0.0012
[2022-11-14 12:30:38,442][main.py][line:2390][INFO] Epoch:[13/30]	 Batch:[300/460]	 Loss Sum:0.7563	 forward Loss:0.2206;0.1732	 backward Loss:0.0771;0.2317	 Sentiment Loss:0.0537
[2022-11-14 12:31:16,766][main.py][line:2390][INFO] Epoch:[13/30]	 Batch:[400/460]	 Loss Sum:0.3255	 forward Loss:0.0018;0.2467	 backward Loss:0.0176;0.0592	 Sentiment Loss:0.0001
[2022-11-14 12:31:39,317][main.py][line:2549][INFO] dev
[2022-11-14 12:31:56,194][main.py][line:1236][INFO] Triplet - Precision: 0.5230263140689924	Recall: 0.47181008762074156	F1: 0.4960993437715687
[2022-11-14 12:31:56,210][main.py][line:1242][INFO] Aspect - Precision: 0.7882352910265282	Recall: 0.720430104944695	F1: 0.7528084869548399
[2022-11-14 12:31:56,210][main.py][line:1247][INFO] Opinion - Precision: 0.7885304631235467	Recall: 0.6528189891607745	F1: 0.7142852163996101
[2022-11-14 12:31:56,210][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.6313725465436371	Recall: 0.5770609298313228	F1: 0.6029957534336216
[2022-11-14 12:31:56,210][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.6414473663110284	Recall: 0.5786350131197774	F1: 0.6084238364007291
[2022-11-14 12:31:56,210][main.py][line:2564][INFO] test
[2022-11-14 12:32:27,701][main.py][line:1236][INFO] Triplet - Precision: 0.6125290008990046	Recall: 0.5387755091045398	F1: 0.5732894030875268
[2022-11-14 12:32:27,701][main.py][line:1242][INFO] Aspect - Precision: 0.8306451590574055	Recall: 0.7392344479922621	F1: 0.782277980727765
[2022-11-14 12:32:27,701][main.py][line:1247][INFO] Opinion - Precision: 0.8395061707666515	Recall: 0.6938775496043316	F1: 0.7597760391251945
[2022-11-14 12:32:27,701][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.7043010733755347	Recall: 0.6267942568736979	F1: 0.6632906392569038
[2022-11-14 12:32:27,701][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.7030162396681758	Recall: 0.6183673456768013	F1: 0.6579799566494896
[2022-11-14 12:32:27,701][main.py][line:2248][INFO] train
[2022-11-14 12:32:28,110][main.py][line:2390][INFO] Epoch:[14/30]	 Batch:[0/460]	 Loss Sum:0.4956	 forward Loss:0.0454;0.0364	 backward Loss:0.3304;0.0448	 Sentiment Loss:0.0385
