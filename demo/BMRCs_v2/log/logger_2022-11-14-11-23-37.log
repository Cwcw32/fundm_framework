[2022-11-14 11:23:37,469][main.py][line:2119][INFO] Namespace(task_type='ASTE', dataset_type='ASTE', data_path='./data', log_path='./log', save_model_path='./checkpoint/2022-11-14-11-23-37-', model_name='BMRC', work_nums=1, mode='train', checkpoint_path='./model/final_2.pth', bert_model_type='../../bert/bert-base-uncased', hidden_size=768, inference_beta=0.8, gpu=True, epoch_num=30, batch_size=2, learning_rate=0.001, tuning_bert_rate=1e-05, warm_up=0.1, beta=1, add_note='')
[2022-11-14 11:23:37,469][main.py][line:2121][INFO] ####################################
[2022-11-14 11:23:37,470][main.py][line:2122][INFO] ####################################
[2022-11-14 11:23:37,470][main.py][line:2124][INFO] loading data......
[2022-11-14 11:23:38,373][main.py][line:2147][INFO] initial optimizer......
[2022-11-14 11:23:38,384][main.py][line:2159][INFO] New model and optimizer from epoch 1
[2022-11-14 11:23:41,923][main.py][line:2196][INFO] begin training......
[2022-11-14 11:23:41,926][main.py][line:2251][INFO] train
[2022-11-14 11:23:43,883][main.py][line:2389][INFO] Epoch:[1/30]	 Batch:[0/460]	 Loss Sum:100.8424	 forward Loss:21.2887;23.0238	 backward Loss:31.2596;23.1847	 Sentiment Loss:2.0856
[2022-11-14 11:24:23,438][main.py][line:2389][INFO] Epoch:[1/30]	 Batch:[100/460]	 Loss Sum:142.9451	 forward Loss:25.5419;43.8696	 backward Loss:39.5769;29.0786	 Sentiment Loss:4.8781
[2022-11-14 11:25:03,327][main.py][line:2389][INFO] Epoch:[1/30]	 Batch:[200/460]	 Loss Sum:53.6739	 forward Loss:9.8041;13.7797	 backward Loss:13.8406;14.2229	 Sentiment Loss:2.0266
[2022-11-14 11:25:43,502][main.py][line:2389][INFO] Epoch:[1/30]	 Batch:[300/460]	 Loss Sum:62.4988	 forward Loss:13.6533;15.9033	 backward Loss:16.6918;14.3491	 Sentiment Loss:1.9013
[2022-11-14 11:26:24,817][main.py][line:2389][INFO] Epoch:[1/30]	 Batch:[400/460]	 Loss Sum:82.234	 forward Loss:14.5783;24.3402	 backward Loss:13.8328;25.7903	 Sentiment Loss:3.6924
[2022-11-14 11:26:48,985][main.py][line:2548][INFO] dev
[2022-11-14 11:27:03,992][main.py][line:1236][INFO] Triplet - Precision: 0.33478260724007564	Recall: 0.22848664620627107	F1: 0.27160445512062675
[2022-11-14 11:27:03,992][main.py][line:1242][INFO] Aspect - Precision: 0.6554054009769905	Recall: 0.34767024964992743	F1: 0.45433209762617166
[2022-11-14 11:27:03,992][main.py][line:1247][INFO] Opinion - Precision: 0.6216216182615047	Recall: 0.3412462897885867	F1: 0.44061256752737554
[2022-11-14 11:27:03,992][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5270270234660336	Recall: 0.27956989147107564	F1: 0.36533912380423467
[2022-11-14 11:27:03,992][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.39999999826086957	Recall: 0.2729970318308693	F1: 0.32451450784390845
[2022-11-14 11:27:03,994][main.py][line:2563][INFO] test
[2022-11-14 11:27:24,109][main.py][line:1236][INFO] Triplet - Precision: 0.39273927263122355	Recall: 0.24285714236151604	F1: 0.30012563045256824
[2022-11-14 11:27:24,109][main.py][line:1242][INFO] Aspect - Precision: 0.7019230735484467	Recall: 0.3492822958151141	F1: 0.46645322889935925
[2022-11-14 11:27:24,109][main.py][line:1247][INFO] Opinion - Precision: 0.7372548990695886	Recall: 0.38367346860474805	F1: 0.5046975349727
[2022-11-14 11:27:24,109][main.py][line:1253][INFO] Aspect-Sentiment - Precision: 0.5817307664339867	Recall: 0.28947368351800556	F1: 0.38658102468178573
[2022-11-14 11:27:24,109][main.py][line:1261][INFO] Aspect-Opinion - Precision: 0.45544554305133483	Recall: 0.28163265248646396	F1: 0.3480449241525434
[2022-11-14 11:27:24,111][main.py][line:2575][INFO] Model saved after epoch 1
[2022-11-14 11:27:24,113][main.py][line:2251][INFO] train
[2022-11-14 11:27:24,553][main.py][line:2389][INFO] Epoch:[2/30]	 Batch:[0/460]	 Loss Sum:47.9871	 forward Loss:11.0279;14.2895	 backward Loss:9.3794;11.0376	 Sentiment Loss:2.2527
[2022-11-14 11:28:05,337][main.py][line:2389][INFO] Epoch:[2/30]	 Batch:[100/460]	 Loss Sum:19.4811	 forward Loss:4.907;3.9933	 backward Loss:4.988;4.2719	 Sentiment Loss:1.321
[2022-11-14 11:28:46,021][main.py][line:2389][INFO] Epoch:[2/30]	 Batch:[200/460]	 Loss Sum:25.0585	 forward Loss:3.2824;9.9963	 backward Loss:4.9119;5.81	 Sentiment Loss:1.0581
