{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ①padding_mask"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "该篇文章的主要motivation是笔者在进行crosss-attention实战时考虑到的，即当Q!=K=V的时候该如何输入相应的padding_mask。\n",
    "要考虑上面的问题，我们往前推，self-attention的时候mask相关内容是什么呢，再往前推，embedding的时候mask是考虑什么呢？\n",
    "那么再从头开始往后推，哪些算子需要输入时提供mask相关内容呢？\n",
    "笔者略加思考，觉得这部分还是非常重要的，因为若batch中长度分布极度不平衡，这势必会很大程度上影响模型的性能。\n",
    "下面分别从实践和理论两方面进行相关分析。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 实践分析"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "问题的来源：\n",
    "    batch中的各个句子长度一般并不相同；\n",
    "本质：\n",
    "    代码需要并行化的处理多个batch的数据而<pad>位置的信息只会产生噪声（未进行相关实验研究，仅猜测）\n",
    "那么在进行后续的处理时，我们就需要进行对应位置的遮掩（mask）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### （1）嵌入时"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\.conda\\envs\\CLMLF\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lenovo\\.conda\\envs\\CLMLF\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\lenovo\\.conda\\envs\\CLMLF\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, RobertaTokenizer\n",
    "from transformers import BertConfig, BertForPreTraining, RobertaForMaskedLM, RobertaModel, RobertaConfig, AlbertModel, AlbertConfig\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at ../../bert/bert-base-uncased/ and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_config = BertConfig.from_pretrained('../../bert/bert-base-uncased/')\n",
    "model = BertForPreTraining.from_pretrained('../../bert/bert-base-uncased/', config=bert_config)\n",
    "bert_model = model.bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\.conda\\envs\\CLMLF\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "text=['hello boy','i am a fish']\n",
    "tokenizer = BertTokenizer.from_pretrained('../../bert/bert-base-uncased/vocab.txt')\n",
    "text_token_list = [tokenizer.tokenize('[CLS]' + t + '[SEP]') for t in text]\n",
    "text_to_id = [tokenizer.convert_tokens_to_ids(text_token) for text_token in text_token_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[['[CLS]', 'hello', 'boy', '[SEP]'],\n ['[CLS]', 'i', 'am', 'a', 'fish', '[SEP]']]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[[101, 7592, 2879, 102], [101, 1045, 2572, 1037, 3869, 102]]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 101, 7592, 2879,  102,    0,    0],\n        [ 101, 1045, 2572, 1037, 3869,  102]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length=[len(i) for i in text_to_id]\n",
    "text_to_id = [torch.LongTensor(b) for b in text_to_id]\n",
    "import torch.nn.utils.rnn as run_utils\n",
    "\n",
    "text_to_id = run_utils.pad_sequence(text_to_id, batch_first=True, padding_value=0)\n",
    "text_to_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[[1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1]]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_l=text_to_id.shape[1]\n",
    "att=[]\n",
    "for length in data_length:\n",
    "    text_mask_cell = [1] * length\n",
    "    text_mask_cell.extend([0] * (max_l - length))\n",
    "    att.append(text_mask_cell[:])\n",
    "att"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.2335e-01,  2.2231e-01,  2.1620e-02,  ..., -4.4586e-02,\n          6.5442e-02,  2.2256e-01],\n        [-6.3776e-01, -2.3101e-01,  9.7291e-01,  ...,  3.6812e-01,\n          1.5373e-01,  4.5564e-02],\n        [-3.4176e-01, -5.4559e-01,  4.7940e-01,  ...,  4.7953e-01,\n          2.8465e-01, -5.8523e-01],\n        [ 7.9941e-01,  1.3761e-02, -1.9604e-01,  ...,  1.8861e-01,\n         -5.4835e-01, -1.9504e-01],\n        [-5.8901e-01,  7.0094e-02,  7.0958e-01,  ...,  2.0668e-02,\n         -9.5173e-04,  5.2641e-02],\n        [-5.9858e-01, -2.3409e-01,  3.3245e-01,  ...,  3.7088e-01,\n          3.9300e-02, -1.1559e-01]], grad_fn=<SelectBackward>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = torch.LongTensor(att)\n",
    "bert_output=bert_model(text_to_id, attention_mask=att)\n",
    "bert_output=bert_output.last_hidden_state\n",
    "bert_output[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，上述输出的 4、5位置并不是0，所以在后续进行词向量的相关操作时，我们有理由对这部分进行mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来我们就应该思考，什么时候mask需要被考虑，什么时候可以不考虑\n",
    "当然一种简单的方法是什么时候都考虑"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在开始之前，我们先记住相关的维度信息，根据笔者的经验（虽然不多），这些维度信息对相关分析都会有很大的帮助"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6, 768])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_id.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# （2）linear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as FF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1],\n         [1],\n         [1],\n         [1],\n         [0],\n         [0]],\n\n        [[1],\n         [1],\n         [1],\n         [1],\n         [1],\n         [1]]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.unsqueeze(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "linear_model = torch.nn.Linear(768, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "linear_output=linear_model(bert_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1522],\n         [ 0.2799],\n         [-0.0567],\n         [ 0.3866],\n         [-0.0196],\n         [-0.1301]],\n\n        [[ 0.2027],\n         [ 0.4311],\n         [ 0.4463],\n         [ 0.5477],\n         [-0.0103],\n         [ 0.5155]]], grad_fn=<AddBackward0>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "att_mask=att.unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "att_mask=att_mask.repeat(1,768,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "att_mask=1-att_mask.permute(0,2,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_mask.byte()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\.conda\\envs\\CLMLF\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:650.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "masked_bert_output=bert_output.data.masked_fill(att_mask.byte(),0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1234,  0.2223,  0.0216,  ..., -0.0446,  0.0654,  0.2226],\n         [-0.6378, -0.2310,  0.9729,  ...,  0.3681,  0.1537,  0.0456],\n         [-0.3418, -0.5456,  0.4794,  ...,  0.4795,  0.2846, -0.5852],\n         [ 0.7994,  0.0138, -0.1960,  ...,  0.1886, -0.5484, -0.1950],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n\n        [[-0.0762,  0.3267, -0.1818,  ..., -0.1450,  0.3118,  0.5097],\n         [ 0.2070,  0.3888, -0.1240,  ..., -0.3377,  0.5565,  0.3100],\n         [ 0.0976,  0.3917,  0.0323,  ..., -0.4654,  0.4817,  0.4301],\n         [ 0.1149,  0.3431,  0.0817,  ..., -0.2893,  0.3845,  0.8167],\n         [-0.1979, -0.2843, -0.4806,  ...,  0.2773,  0.6106, -0.5674],\n         [ 0.8017,  0.1640, -0.3317,  ..., -0.0054, -0.7692, -0.4068]]])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_bert_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "masked_linear_output=linear_model(masked_bert_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1522],\n         [ 0.2799],\n         [-0.0567],\n         [ 0.3866],\n         [ 0.0183],\n         [ 0.0183]],\n\n        [[ 0.2027],\n         [ 0.4311],\n         [ 0.4463],\n         [ 0.5477],\n         [-0.0103],\n         [ 0.5155]]], grad_fn=<AddBackward0>)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_linear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1522],\n         [ 0.2799],\n         [-0.0567],\n         [ 0.3866],\n         [-0.0196],\n         [-0.1301]],\n\n        [[ 0.2027],\n         [ 0.4311],\n         [ 0.4463],\n         [ 0.5477],\n         [-0.0103],\n         [ 0.5155]]], grad_fn=<AddBackward0>)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6, 1])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# 到这里我们就可以发现，实际上是不构成任何影响的，从理论的角度来说，这部分在最后loss的时候屏蔽即可"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# （3）max/min"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.min(\nvalues=tensor([[ 0.1522,  0.2799, -0.0567,  0.3866, -0.0196, -0.1301],\n        [ 0.2027,  0.4311,  0.4463,  0.5477, -0.0103,  0.5155]],\n       grad_fn=<MinBackward0>),\nindices=tensor([[0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0]]))"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这边也是同理，虽然会增加一些计算开销，但实际上对\n",
    "max_output=torch.min(linear_output,dim=2)\n",
    "max_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.min(\nvalues=tensor([[-0.1301],\n        [-0.0103]], grad_fn=<MinBackward0>),\nindices=tensor([[5],\n        [4]]))"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_output=torch.min(linear_output,dim=1)\n",
    "max_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这里就出现问题了，所以在max和min的时候要注意遮掩，具体看使用max还是使用min"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# （4） RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(input_size=768,hidden_size=50,num_layers=1, bidirectional=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# 这里先介绍两个函数\n",
    "# pack_padded_sequence 和 pad_packed_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pack_padded_sequence\n",
    "这个函数主要做了两件事： pad 和封装\n",
    "因为在rnn模型中，一般先将batch中的数据按照一个时间步一个时间步喂入模型的，这个包的主要作用就是将按照样本堆叠的数据，抽取出时间步这个维度重新堆叠。\n",
    "\n",
    "input： pad_sequence 的结果\n",
    "length：batch 中各个句子的实际长度\n",
    "batch_first: batch 是否在第一位，默认值是False，上面的例子指定为了True，因为是二维，方便观察理解，一般放入lstm或者gru是需要时间步放在第一位的。\n",
    "enforce_sorted：如果是 True ，则输入应该是按长度降序排序的序列。如果是 False ，会在函数内部进行排序。默认值为 True。\n",
    "需要注意的是，默认条件下，我们必须把输入数据按照序列长度从大到小排列后才能送入 pack_padded_sequence ，否则会报错。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#注意上面所说，需要把输入数据按照序列长度从大到小排列后才能送入"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}